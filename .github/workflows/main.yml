name: Scraping & Nettoyage Immobilier

on:
  workflow_dispatch:  # Permits manual triggering

permissions:
  contents: write # Necessary to push changes

jobs:
  scraping:
    runs-on: ubuntu-latest # Uses the latest Ubuntu runner environment for the job

    steps:
    - name: Checkout repo # Checks out the repository code
      uses: actions/checkout@v3

    - name: Set up Python # Sets up Python environment
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies # Installs required Python packages
      run: |
        python -m pip install --upgrade pip
        pip install scrapy pandas

    - name: Run Scrapy spider & save cleaned data # Executes the Scrapy spider and saves output to CSV
      run: |
        cd src/webscraping
        scrapy crawl french_immobilier -O ../../annonces.json

    - name: Clean data with Python script # Runs the cleaning script to process the scraped data
      run: python src/clean.py annonces.json

    - name: Commit & push CSV # Commits and pushes the updated CSV file back to the repository (github-actions[bot] is the user)
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add annonces_propres.csv
        git commit -m "Update CSV automatique" || echo "No changes to commit"
        git push https://x-access-token:${{ secrets.PAT_TOKEN }}@github.com/${{ github.repository }} HEAD:main
      env: # Environment variable for authentication
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # GitHub token for authentication
